{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BitCoinPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1_GDX1aMRbAe2QalEt85N_29q62gBMGLy",
      "authorship_tag": "ABX9TyPhhLPuUJNBNzjZyaaAT3//",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asutosh07/Bitcoin-Stock-Prediction-Using-LSTMs/blob/master/BitCoinPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUAdglVPWYTX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDYFX3zK4Z85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQOESyPEleyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlWq5_jWl0k4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPco_PwZnIfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "files = [\"BTC-USD\",\"ETH-USD\",\"LTC-USD\",\"BCH-USD\"]\n",
        "\n",
        "for i in files:\n",
        "  file_path = f'/content/drive/My Drive/{i}.csv'\n",
        "  temp_file = pd.read_csv(file_path,names=['timestamp', 'low', 'high', 'open', 'close', 'volume'])\n",
        "  \n",
        "  temp_file.rename(columns={\"close\": f\"{i}_close\", \"volume\": f\"{i}_volume\"}, inplace=True)\n",
        "  temp_file.set_index(\"timestamp\",inplace=True)\n",
        "  temp_file = temp_file[[f\"{i}_close\",f\"{i}_volume\"]]\n",
        "  if len(df)==0:\n",
        "    df = temp_file\n",
        "  else:\n",
        "    df = df.join(temp_file)\n",
        "\n",
        "df.fillna(method=\"ffill\",inplace=True)\n",
        "df.dropna(inplace = True)\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAqPdlEv8M7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prev_seq_len = 60\n",
        "futurePeriodOfPrediction = 3\n",
        "coin_pred = \"BTC-USD\" "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0dbDKsg81jq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def targetValue(current_val,future_val):\n",
        "  if float(future_val)>float(current_val):\n",
        "    return 1\n",
        "  return 0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sniSmKMy9M5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['target'] = list(map(targetValue,df[f'{coin_pred}_close'],df[f'{coin_pred}_close'].shift(-futurePeriodOfPrediction)))\n",
        "#df = df.replace([np.inf, -np.inf], np.nan)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOee3ssQBuiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BVy4QQAB0u7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_timestamp = sorted(df.index.values)\n",
        "val_time_edge = sorted(df.index.values)[-int(0.05*len(sorted_timestamp))]\n",
        "\n",
        "validation_set = df[(df.index>=val_time_edge)]\n",
        "train = df[(df.index<val_time_edge)]\n",
        "\n",
        "print(train.head())\n",
        "print(validation_set.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFoOCzy6czh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVH6fHW-c4xn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing_df(df):\n",
        "\n",
        "  df = df.replace([np.inf, -np.inf], np.nan)\n",
        "  for col in df.columns:\n",
        "\n",
        "    if col!=\"target\":\n",
        "      df[col] = df[col].pct_change()\n",
        "      \n",
        "      df.dropna(inplace=True)\n",
        "      #print(df)\n",
        "      df[col] = preprocessing.scale(df[col].values)\n",
        "      #print(df[col])\n",
        "\n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  sequential_data = []\n",
        "  prev_days = deque(maxlen =prev_seq_len )\n",
        "\n",
        "  for i in df.values:\n",
        "    prev_days.append([j for j in i[::-1]])\n",
        "    if len(prev_days) == prev_seq_len:\n",
        "      sequential_data.append([np.array(prev_days),i[-1]])\n",
        "  random.shuffle(sequential_data)\n",
        "\n",
        "  buys = []\n",
        "  sells = []\n",
        "\n",
        "  for seq,target in sequential_data:\n",
        "    if target == 0:\n",
        "      sells.append([seq,target])\n",
        "    elif target==1:\n",
        "      buys.append([seq,target])\n",
        "  \n",
        "  random.shuffle(buys)\n",
        "  random.shuffle(sells)\n",
        "\n",
        "  lower = min(len(buys),len(sells))\n",
        "  #print(lower)\n",
        "  buys = buys[:lower]\n",
        "  sells = sells[:lower]\n",
        "\n",
        "  sequential = buys+sells\n",
        "  random.shuffle(sequential_data)\n",
        "  print(\"Buys , Sells: \",len(buys),len(sells))\n",
        "  x_set =[]\n",
        "  y_set =[]\n",
        "\n",
        "  for seq,target in sequential_data:\n",
        "    x_set.append(seq)\n",
        "    y_set.append(target)\n",
        "\n",
        "  return np.array(x_set),y_set\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_oN7KrmdxIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x,train_y = preprocessing_df(train)\n",
        "print(\"Size of training set\",len(train_x))\n",
        "val_x , val_y = preprocessing_df(validation_set)\n",
        "print(\"Size of validation set\",len(val_x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXvBSauPp5AV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFIk_M3AqVqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,input_shape=(train_x.shape[1:]),activation='relu',return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(LSTM(128,activation='relu',return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(LSTM(128,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D0tIGCSs1up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = np.asarray(train_x)\n",
        "train_y = np.asarray(train_y)\n",
        "val_x = np.asarray(val_x)\n",
        "val_y = np.asarray(val_y)\n",
        "\n",
        "optimiser = tf.keras.optimizers.Adam()\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=optimiser,\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "model.fit(\n",
        "    train_x,train_y,\n",
        "    batch_size = 32,\n",
        "    epochs = 40,\n",
        "    validation_data = (val_x,val_y)\n",
        ")\n",
        "\n",
        "score = model.evaluate(val_x,val_y,verbose = 0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy: ',score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}